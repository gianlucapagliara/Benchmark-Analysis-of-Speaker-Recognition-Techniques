{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0a92a37186c380a60507f40bb2112126893146ebedb219986cd10724b91922d22",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 0 bytes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'data/voxceleb2/'\n",
    "\n",
    "problems = []\n",
    "\n",
    "for idx in tqdm(os.listdir(PATH)):\n",
    "    currentidx_path = f'{PATH}{idx}/'\n",
    "    for f in os.listdir(currentidx_path):\n",
    "        currentfolder_path = f'{currentidx_path}{f}/'\n",
    "        for w in os.listdir(currentfolder_path):\n",
    "            current_file = f'{currentfolder_path}{w}'\n",
    "            if os.stat(current_file).st_size == 0:\n",
    "                problems.append(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Problems found:')\n",
    "print(len(problems))\n",
    "print('Folders:')\n",
    "print(set([p.split('/')[2] for p in problems]))"
   ]
  },
  {
   "source": [
    "# Slow loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'data/voxceleb2/'\n",
    "\n",
    "problems = []\n",
    "\n",
    "for idx in tqdm(os.listdir(PATH)):\n",
    "    currentidx_path = f'{PATH}{idx}/'\n",
    "    for f in os.listdir(currentidx_path):\n",
    "        currentfolder_path = f'{currentidx_path}{f}/'\n",
    "        for w in os.listdir(currentfolder_path):\n",
    "            current_file = f'{currentfolder_path}{w}'\n",
    "            if os.stat(current_file).st_size == 0:\n",
    "                loadWAV(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.Sampler import Sampler\n",
    "import torch\n",
    "import importlib\n",
    "from easydict import EasyDict\n",
    "\n",
    "config = {\n",
    "    \"train_dataset\": \"VoxCeleb2\",\n",
    "    \"train_list\": \"data/train_list.txt\",\n",
    "    \"train_path\": \"data/voxceleb2/\",\n",
    "    \"max_frames\": 200,\n",
    "    \"max_epoch\": 500,\n",
    "    \"batch_size\": 400,\n",
    "    \"nDataLoaderThread\": 5,\n",
    "    \"max_seg_per_spk\": 500,\n",
    "    \"sampler\": True,\n",
    "    \"nPerSpeaker\": 2,\n",
    "    \"seed\": 1337,\n",
    "\n",
    "    \"distributed\": False,\n",
    "}\n",
    "\n",
    "config = EasyDict(config)\n",
    "\n",
    "TrainDataset = importlib.import_module(\n",
    "                'datasets.' + config.train_dataset).__getattribute__(config.train_dataset)\n",
    "train_dataset = TrainDataset(**vars(config))\n",
    "sampler = Sampler(train_dataset, **vars(config)) if config.sampler else None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.nDataLoaderThread,\n",
    "    sampler=sampler,\n",
    "    pin_memory=False,\n",
    "    #worker_init_fn=worker_init_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "total_iterations=len(train_loader)\n",
    "loop_time = time.time()\n",
    "for x, y, f in train_loader:\n",
    "    loop_time = time.time()-loop_time\n",
    "    #times.append((loop_time, 0))\n",
    "    print(f'Loop: {loop_time}s')\n",
    "    loop_time = time.time()"
   ]
  },
  {
   "source": [
    "# Custom train list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'data/voxceleb2/'\n",
    "\n",
    "ids = []\n",
    "files = []\n",
    "\n",
    "for idx in tqdm(os.listdir(PATH)):\n",
    "    currentidx_path = f'{PATH}{idx}/'\n",
    "    for f in os.listdir(currentidx_path):\n",
    "        currentfolder_path = f'{currentidx_path}{f}/'\n",
    "        for w in os.listdir(currentfolder_path):\n",
    "            files.append(f'{idx}/{f}/{w}')\n",
    "            ids.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_FILE = 'data/train_list.txt'\n",
    "\n",
    "with open(LIST_FILE, 'w') as f:\n",
    "    for i, n in zip(ids, files):\n",
    "        f.write(f'{i} {n}\\n')"
   ]
  },
  {
   "source": [
    "# Custom test list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'data/voxceleb1/'\n",
    "\n",
    "existing_ids = []\n",
    "existing_files = []\n",
    "\n",
    "for idx in tqdm(os.listdir(PATH)):\n",
    "    currentidx_path = f'{PATH}{idx}/'\n",
    "    for f in os.listdir(currentidx_path):\n",
    "        currentfolder_path = f'{currentidx_path}{f}/'\n",
    "        for w in os.listdir(currentfolder_path):\n",
    "            existing_files.append(f'{idx}/{f}/{w}')\n",
    "            existing_ids.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "unique_ids = set(existing_ids)\n",
    "\n",
    "to_write = []\n",
    "\n",
    "for idx in tqdm(unique_ids):\n",
    "    equivalent_indices = [i for i, x in enumerate(existing_ids) if x == idx]\n",
    "    equivalent_list = [f'1 {existing_files[equivalent_indices[0]]} {existing_files[e]}' for e in equivalent_indices[1:]]\n",
    "    not_equivalent_indices = [i for i, x in enumerate(existing_ids) if x != idx]\n",
    "    not_equivalent_indices = sample(not_equivalent_indices, len(equivalent_list))\n",
    "    not_equivalent_list = [f'0 {existing_files[equivalent_indices[0]]} {existing_files[e]}' for e in not_equivalent_indices]\n",
    "    merge = [None]*(len(equivalent_list)+len(not_equivalent_list))\n",
    "    merge[::2] = equivalent_list\n",
    "    merge[1::2] = not_equivalent_list\n",
    "    to_write.extend(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_FILE = 'data/test_list.txt'\n",
    "\n",
    "with open(LIST_FILE, 'w') as f:\n",
    "    for l in to_write:\n",
    "        f.write(f'{l}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
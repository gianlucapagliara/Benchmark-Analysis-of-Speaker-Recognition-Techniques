{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitconda8427c4b38768436f877996e07fe52583",
   "display_name": "Python 3.6.13 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8036e4c51114ddf1e2050050a6c672e5d73fadc6671b7cf90c94b7a7c6aa158a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\giang\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from agents.base import BaseAgent\n",
    "from graphs.models.SpeakerNet import SpeakerNet\n",
    "from utils.misc import print_cuda_statistics\n",
    "from utils.metrics import AverageMeter\n",
    "from datasets.Sampler import Sampler\n",
    "\n",
    "import tqdm as t\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "\n",
    "class Trainer(BaseAgent):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # GPU and CUDA\n",
    "        # Construct the flag and make sure that cuda is available\n",
    "        self.cuda = torch.cuda.is_available() & self.config.cuda\n",
    "        if self.cuda:\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            torch.cuda.manual_seed_all(self.config.seed)\n",
    "            torch.cuda.set_device(self.config.gpu_device)\n",
    "            self.logger.info(\"Operation will be on ***** GPU-CUDA ***** \")\n",
    "            print_cuda_statistics()\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            torch.manual_seed(self.config.seed)\n",
    "            self.logger.info(\"Operation will be on ***** CPU ***** \")\n",
    "        self.gpu = config.gpu_device\n",
    "        self.config.device = self.device\n",
    "\n",
    "        # Datasets\n",
    "        self.to_train = config.train\n",
    "        if self.to_train:\n",
    "            TrainDataset = importlib.import_module(\n",
    "                'datasets.' + config.train_dataset).__getattribute__(config.train_dataset)\n",
    "            self.train_dataset = TrainDataset(**vars(config))\n",
    "            self.sampler = Sampler(self.train_dataset, **vars(config)) if self.config.sampler else None\n",
    "            self.train_loader = torch.utils.data.DataLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=config.batch_size,\n",
    "                num_workers=config.nDataLoaderThread,\n",
    "                sampler=self.sampler,\n",
    "                pin_memory=False,\n",
    "                #worker_init_fn=worker_init_fn,\n",
    "                drop_last=True,\n",
    "            )\n",
    "\n",
    "        self.to_test = config.test\n",
    "        if self.to_test:\n",
    "            TestDataset = importlib.import_module(\n",
    "                'datasets.' + config.test_dataset).__getattribute__(config.test_dataset)\n",
    "            self.test_dataset = TestDataset(**vars(config))\n",
    "            self.test_loader = torch.utils.data.DataLoader(\n",
    "                self.test_dataset,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                num_workers=config.nDataLoaderThread,\n",
    "                drop_last=False,\n",
    "            )\n",
    "\n",
    "        # Loss\n",
    "        LossFunction = importlib.import_module(\n",
    "            'graphs.losses.'+config.loss_function).__getattribute__('LossFunction')\n",
    "        self.__loss__ = LossFunction(**vars(config))\n",
    "        self.__loss__ = self.__loss__.to(self.device)\n",
    "\n",
    "        # Model\n",
    "        Model = importlib.import_module(\n",
    "            'graphs.models.' + config.model).__getattribute__(config.model)\n",
    "        self.__model__ = SpeakerNet(\n",
    "            Model(**vars(config)), self.__loss__, self.device, config.nPerSpeaker)\n",
    "        self.__model__ = self.__model__.to(self.device)\n",
    "\n",
    "        # Model Loading (if not found start from scratch)\n",
    "        self.load_checkpoint(self.config.initial_model)\n",
    "\n",
    "        # Optimizer\n",
    "        Optimizer = importlib.import_module(\n",
    "            'graphs.optimizers.' + config.optimizer).__getattribute__('Optimizer')\n",
    "        self.__optimizer__ = Optimizer(\n",
    "            self.__model__.parameters(), **vars(config))\n",
    "\n",
    "        # Scheduler\n",
    "        Scheduler = importlib.import_module(\n",
    "            'graphs.schedulers.'+config.scheduler).__getattribute__('Scheduler')\n",
    "        self.__scheduler__, self.lr_step = Scheduler(\n",
    "            self.__optimizer__, **vars(config))\n",
    "        assert self.lr_step in ['epoch', 'iteration']\n",
    "\n",
    "        # Scaler\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "        # Tensorboard Writer\n",
    "        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir)\n",
    "\n",
    "        # Counters initialization\n",
    "        self.current_epoch = 0\n",
    "        self.current_iteration = 0\n",
    "        self.best_valid_acc = 0\n",
    "\n",
    "        # Others\n",
    "        self.verbose = config.verbose\n",
    "        self.mixedprec = config.mixedprec\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        filename = self.config.checkpoint_dir + filename\n",
    "        try:\n",
    "            self.logger.info(\"Loading checkpoint '{}'\".format(filename))\n",
    "            checkpoint = torch.load(filename)\n",
    "\n",
    "            self.current_epoch = checkpoint['epoch']\n",
    "            self.current_iteration = checkpoint['iteration']\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "            self.logger.info(\"Checkpoint loaded successfully from '{}' at (epoch {}) at (iteration {})\\n\"\n",
    "                             .format(self.config.checkpoint_dir, checkpoint['epoch'], checkpoint['iteration']))\n",
    "        except OSError as e:\n",
    "            self.logger.info(\"No checkpoint exists from '{}'. Skipping...\".format(\n",
    "                self.config.checkpoint_dir))\n",
    "\n",
    "    def save_checkpoint(self, file_name=\"checkpoint.pth.tar\", is_best=0):\n",
    "        state = {\n",
    "            'epoch': self.current_epoch,\n",
    "            'iteration': self.current_iteration,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }\n",
    "        # Save the state\n",
    "        torch.save(state, self.config.checkpoint_dir + file_name)\n",
    "        # If it is the best copy it to another file 'model_best.pth.tar'\n",
    "        if is_best:\n",
    "            shutil.copyfile(self.config.checkpoint_dir + file_name,\n",
    "                            self.config.checkpoint_dir + 'model_best.pth.tar')\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            if self.to_train:\n",
    "                self.train()\n",
    "            if self.to_test:\n",
    "                self.validate()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"You have entered CTRL+C... Wait to finalize.\")\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.current_epoch, self.config.max_epoch):\n",
    "            self.current_epoch = epoch\n",
    "            if self.config.sampler:\n",
    "                self.sampler.set_epoch(epoch)\n",
    "\n",
    "            loss, acc = self.train_one_epoch()\n",
    "\n",
    "            valid_acc = self.validate()\n",
    "            is_best = valid_acc > self.best_valid_acc\n",
    "            if is_best:\n",
    "                self.best_valid_acc = valid_acc\n",
    "            self.save_checkpoint(is_best=is_best)\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        # Set the model to be in training mode\n",
    "        self.__model__.train()\n",
    "\n",
    "        # Initialize your average meters\n",
    "        epoch_loss = AverageMeter()\n",
    "        epoch_top1 = AverageMeter()  # EER or accuracy\n",
    "\n",
    "        # Initialize tqdm\n",
    "        #t.tqdm.monitor_interval = 0\n",
    "        #tqdm_batch = tqdm(self.train_loader, total=len(self.train_loader),desc=\"Epoch {}\".format(self.current_epoch+1))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        total_iterations=len(self.train_loader)\n",
    "        #for x, y in tqdm_batch:\n",
    "        for x, y in self.train_loader: \n",
    "            loop_time = time.time()-start_time\n",
    "            \n",
    "            x = x.transpose(1, 0)\n",
    "            y = torch.LongTensor(y).to(self.device)\n",
    "\n",
    "            #prepare_time = time.time()-start_time\n",
    "            prepare_time = time.time()-start_time-loop_time\n",
    "\n",
    "            self.__model__.zero_grad()\n",
    "\n",
    "            if self.mixedprec:\n",
    "                with autocast():\n",
    "                    cur_loss, curr_top1 = self.__model__(x, y)\n",
    "                self.scaler.scale(cur_loss).backward()\n",
    "                self.scaler.step(self.__optimizer__)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                cur_loss, curr_top1 = self.__model__(x, y)\n",
    "                cur_loss.backward()\n",
    "                self.__optimizer__.step()\n",
    "\n",
    "            if self.lr_step == 'iteration':\n",
    "                self.__scheduler__.step()\n",
    "\n",
    "            # Meters update\n",
    "            epoch_loss.update(cur_loss.item())\n",
    "            epoch_top1.update(curr_top1.item(), x.size(0))\n",
    "\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            self.summary_writer.add_scalar(\n",
    "                \"epoch/loss\", epoch_loss.val, self.current_iteration)\n",
    "            self.summary_writer.add_scalar(\n",
    "                \"epoch/accuracy\", epoch_top1.val, self.current_iteration)\n",
    "            # Logging\n",
    "            process_time = time.time()-start_time-prepare_time-loop_time\n",
    "            total = process_time+prepare_time+loop_time\n",
    "            perc_loop = loop_time/total*100\n",
    "            perc_proc = process_time/total*100\n",
    "            perc_prep = prepare_time/total*100\n",
    "            #tqdm_batch.set_description(\"Epoch {} | Loss {:f} TEER/TAcc {:2.3f}% | Comput. Eff.: {:.2f}% \".format(self.current_epoch+1, epoch_loss.val, epoch_top1.val, efficiency), refresh=True)\n",
    "            #tqdm_batch.set_description(\"Epoch {} | Loss {:f} TEER/TAcc {:2.3f}% | Loop: {:.2f}% - Preparation: {:.2f}% - Process: {:.2f}% \".format(self.current_epoch+1, epoch_loss.val, epoch_top1.val, perc_loop, perc_prep, perc_proc), refresh=True)\n",
    "\n",
    "            sys.stdout.write(\"\\rEpoch-{} ({}/{}) | Loss {:f} TEER/TAcc {:2.3f}% | Time remaining: {} | Loop: {:.2f}% - Preparation: {:.2f}% - Process: {:.2f}%\"\n",
    "                    .format(self.current_epoch+1, self.current_iteration, total_iterations, epoch_loss.val, epoch_top1.val,\n",
    "                             str(datetime.timedelta(seconds=total*(total_iterations-self.current_iteration))),\n",
    "                             perc_loop, perc_prep, perc_proc));\n",
    "            sys.stdout.flush();\n",
    "            start_time = time.time()\n",
    "\n",
    "        if self.lr_step == 'epoch':\n",
    "            self.__scheduler__.step()\n",
    "\n",
    "        #tqdm_batch.close()\n",
    "        self.logger.info(\"Training at epoch-{} completed. | Loss {:f} TEER/TAcc {:2.3f}%  \".format(\n",
    "            self.current_epoch+1, epoch_loss.val, epoch_top1.val))\n",
    "\n",
    "        return (epoch_loss.val, epoch_top1.val)\n",
    "\n",
    "    def validate(self):\n",
    "        self.__model__.eval()\n",
    "\n",
    "        lines = []\n",
    "        files = []\n",
    "        feats = {}\n",
    "        tstart = time.time()\n",
    "\n",
    "        # Extract features for every image\n",
    "        for idx, data in enumerate(self.test_loader):\n",
    "            inp1 = data[0][0].to(self.device)\n",
    "            ref_feat = self.__model__(inp1).detach().cpu()\n",
    "            feats[data[1][0]] = ref_feat\n",
    "            telapsed = time.time() - tstart\n",
    "\n",
    "            if idx % self.config.print_interval == 0:\n",
    "                sys.stdout.write(\"\\rReading {:d} of {:d}: {:.2f} Hz, embedding size {:d}\".format(\n",
    "                    idx, len(self.test_dataset), idx/telapsed, ref_feat.size()[1]))\n",
    "\n",
    "        print('')\n",
    "        all_scores = []\n",
    "        all_labels = []\n",
    "        all_trials = []\n",
    "        tstart = time.time()\n",
    "\n",
    "        # Read files and compute all scores\n",
    "        for idx, line in enumerate(lines):\n",
    "\n",
    "            data = line.split()\n",
    "\n",
    "            # Append random label if missing\n",
    "            if len(data) == 2:\n",
    "                data = [random.randint(0, 1)] + data\n",
    "\n",
    "            ref_feat = feats[data[1]].to(self.device)\n",
    "            com_feat = feats[data[2]].to(self.device)\n",
    "\n",
    "            if self.__model__.module.__L__.test_normalize:\n",
    "                ref_feat = F.normalize(ref_feat, p=2, dim=1)\n",
    "                com_feat = F.normalize(com_feat, p=2, dim=1)\n",
    "\n",
    "            dist = F.pairwise_distance(\n",
    "                ref_feat.unsqueeze(-1), com_feat.unsqueeze(-1).transpose(0, 2)).detach().cpu().numpy()\n",
    "\n",
    "            score = -1 * np.mean(dist)\n",
    "\n",
    "            all_scores.append(score)\n",
    "            all_labels.append(int(data[0]))\n",
    "            all_trials.append(data[1]+\" \"+data[2])\n",
    "\n",
    "            if idx % self.config.print_interval == 0:\n",
    "                telapsed = time.time() - tstart\n",
    "                sys.stdout.write(\"\\rComputing {:d} of {:d}: {:.2f} Hz\".format(\n",
    "                    idx, len(lines), idx/telapsed))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        return (all_scores, all_labels, all_trials)\n",
    "\n",
    "    def finalize(self):\n",
    "        self.logger.info(\"Finalizing the operation...\")\n",
    "        self.save_checkpoint()\n",
    "        self.summary_writer.export_scalars_to_json(\n",
    "            \"{}all_scalars.json\".format(self.config.summary_dir))\n",
    "        self.summary_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO]: Experiment: VGGVox.\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "\n",
    "from datasets.Sampler import Sampler\n",
    "from graphs.models.SpeakerNet import SpeakerNet\n",
    "from graphs.models.VGGVox import VGGVox\n",
    "\n",
    "#from agents.trainer import Trainer\n",
    "\n",
    "\n",
    "from utils.config import *\n",
    "\n",
    "#JSON = 'configs/VGGVox.json'\n",
    "#JSON = 'configs/ResNetSE34L.json'\n",
    "JSON = 'configs/Test.json'\n",
    "\n",
    "config = process_config(JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[INFO]: Operation will be on ***** GPU-CUDA ***** \n",
      "[INFO]: __Python VERSION:  3.6.13 (default, Feb 19 2021, 05:17:09) [MSC v.1916 64 bit (AMD64)]\n",
      "[INFO]: __pyTorch VERSION:  1.8.1+cu102\n",
      "[INFO]: __CUDA VERSION\n",
      "[INFO]: __CUDNN VERSION:  7605\n",
      "[INFO]: __Number CUDA Devices:  1\n",
      "[INFO]: __Devices\n",
      "[INFO]: Active CUDA Device: GPU 0\n",
      "[INFO]: Available devices  1\n",
      "[INFO]: Current cuda device  0\n",
      "[INFO]: Loading checkpoint 'experiments\\VGGVox\\checkpoints/'\n",
      "[INFO]: No checkpoint exists from 'experiments\\VGGVox\\checkpoints/'. Skipping...\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(trainer.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch-1 (2/2) | Loss 0.747073 TEER/TAcc 50.000% | Time remaining: 0:00:00 | Loop: 2.56% - Preparation: 0.00% - Process: 97.44%[INFO]: Training at epoch-1 completed. | Loss 0.747073 TEER/TAcc 50.000%  \n",
      "Reading 0 of 8: 0.00 Hz, embedding size 512\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-041e2033e90a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-e806c77b176f>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e806c77b176f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mis_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_valid_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_valid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}